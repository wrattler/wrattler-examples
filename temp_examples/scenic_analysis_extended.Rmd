---
title: "Scenic analysis"
output: scenic_analysis_R_notebook
---

This notebook provides some scratch R analysis/visualisation of crime data (joined with deprivation indices) and scenic ratings.

```{r}
#getwd()
#setwd("/Users/ahadjitofi/Desktop)
df = read.csv("crime_data_12_11_19.csv")
crime_subset_df = df[ which(df$crime_category=='total_count'), ]
```
```{r}
# install.packages("ggplot2")
library(ggplot2)
ggplot(crime_subset_df, aes(crime_count)) + geom_histogram(binwidth = 500)
ggplot(crime_subset_df, aes(population_density_area_hectares)) + geom_histogram(binwidth = 10)
ggplot(crime_subset_df, aes(employment_score_rate)) + geom_histogram(binwidth = 0.05)
ggplot(crime_subset_df, aes(education_skills_and_training_score)) + geom_histogram(binwidth = 1)
ggplot(crime_subset_df, aes(income_score_rate)) + geom_histogram(binwidth = 0.05)
ggplot(crime_subset_df, aes(barriers_to_housing_and_services_score)) + geom_histogram(binwidth = 2)
ggplot(crime_subset_df, aes(scenic_rating)) + geom_histogram(binwidth = 0.05)
ggplot(crime_subset_df, aes(health_deprivation_and_disability_score)) + geom_histogram(binwidth = 0.1)
ggplot(crime_subset_df, aes(living_environment_score)) + geom_histogram(binwidth = 1)
```

* The crime count distribution plot above shows that the majority of the LSOAs have a total count of less than 5000 crimes accumulated over the 9 years. 
* The population density plot shows that the majority of LSOAs have similar population densities.

To first investigate visually whether there might be a relationship between scenicness and crime occurences, we can create bins of the LSOAs according to crime count and then plot/overlay the ratings (e.g. scenicness, income rate, etc.) for each bin in different colours

```{r}
#install.packages("mltools")
library(mltools)

binned_data = bin_data(crime_subset_df$mean_monthly_crime_count, bins=4, binType = "quantile")
bin_labels <- as.integer(binned_data) - 1L
crime_subset_df["label"] <- bin_labels

cols <- c("scenic_rating",
          "population_density_area_hectares",
          "employment_score_rate",
          "education_skills_and_training_score",
          "income_score_rate",
          "barriers_to_housing_and_services_score",
          "health_deprivation_and_disability_score",
          "living_environment_score")
d <- data.frame(column = cols, bin_width = c(0.05, 10, 0.05, 1, 0.05, 2, 0.1, 1))

for (i in seq_len(nrow(d))) {
  feature <- as.character(d[i,]$column)
  w <- d[i,]$bin_width
  
  plot <- ggplot(crime_subset_df, aes_string(feature)) +
  geom_histogram(data=subset(crime_subset_df, label == 0), binwidth=w, color=NA, fill = "#E89005", alpha = 0.9) + # lowest crime count
  geom_histogram(data=subset(crime_subset_df, label == 1), binwidth=w, color=NA, fill = "#2292A4", alpha = 0.9) +
  geom_histogram(data=subset(crime_subset_df, label == 2), binwidth=w, color=NA, fill = "#485665", alpha = 0.9) +
  geom_histogram(data=subset(crime_subset_df, label == 3), binwidth=w, fill = "#003B36", alpha = 0.9) # highest crime count
  print(plot)
}

```

The four colours in the above plots represent different ranges of percentiles of the data according to crime count. For example, the dark green bars represents the 75th-100th percentile of LSOAs (have the highest number of crimes), and the orange represents the 0-25th percentile of LSOAs (the lowest number of crimes). Blue is 25th-50th, and grey is 50th-75th.

The general observations from these plots are:
* There is a wider distribution of values of given scores in the higher percentile ranges (i.e. ranges that contain LSOAs which more instances of crime).
* LSOAs in the higher percentile ranges that generally have higher scores on indices of deprivation (and lower score on scenic rating).

The above plots show that the data generally follows a trend that we might expect - that LSOAs with higher crime counts score higher on indices of deprivation, and have lower scenic ratings. We now run some analysis to qualify this relationship quantitatively.

```{r}
#install.packages("AER")
library(AER)

# Run Poisson model
summary(m1 <- glm(crime_count ~ scenic_rating, 
                        family="poisson", 
                        data=crime_subset_df))

# Check that a model with scenic rating is better than a null model - drop in deviance test (https://bookdown.org/roback/bookdown-bysh/ch-poissonreg.html)
model0 = glm(crime_count ~ 1, family="poisson", data=crime_subset_df)
anova(model0, m1, test = "Chisq")

# Add deprivation scores
summary(m2 <- glm(crime_count ~ scenic_rating + 
                                      income_score_rate + 
                                      employment_score_rate + 
                                      education_skills_and_training_score + 
                                      health_deprivation_and_disability_score + 
                                      barriers_to_housing_and_services_score +
                                      living_environment_score, 
                        family="poisson", 
                        data=crime_subset_df))

# Add population density
summary(m3 <- glm(crime_count ~ scenic_rating + 
                                      income_score_rate + 
                                      employment_score_rate + 
                                      education_skills_and_training_score + 
                                      health_deprivation_and_disability_score + 
                                      barriers_to_housing_and_services_score +
                                      living_environment_score + 
                                      population_density_area_hectares, 
                        family="poisson", 
                        data=crime_subset_df))

# Check that a model with scenic rating is better than a model with multiple predictors - drop in deviance test
anova(m1, m2, test = "Chisq")

# Check for overdispersion
dispersiontest(m1)
```

Above we have run three Poisson regression models, each time adding in more "predictor" variables. By controlling for important covariates, we can obtain more precise estimates of the relationship between scenic rating and number of crimes in an LSOA. We also run an overdispersion test - to test whether one of the assumptions of the Poisson distribution has been violated. We also perform drop in deviance tests to test that a model with scenic rating is in fact better than a null model, as well to compare a model with scenic rating versus a model with the other predictor variables too.

Whilst we see that the model with all of the predictor variables - where each has a statistically significant influence on the crime rate - is the best (/most powerful) model, according to AIC, we have also confirmed that the data is overdispersed. Hence, below we run a negative binomial regression model, which does not make the same mean==variance assumption that Poisson regression models do, and has an extra parameter to account for the dispersion.

```{r}
library(MASS)

# Run negative binomial regression model
summary(mnb1 <- glm.nb(crime_count ~ scenic_rating + 
                                    income_score_rate + 
                                    employment_score_rate + 
                                    education_skills_and_training_score + 
                                    health_deprivation_and_disability_score + 
                                    barriers_to_housing_and_services_score + 
                                    living_environment_score + 
                                    population_density_area_hectares, 
                      data=crime_subset_df))
```
```{r}

# Run negative binomial regression model removing non significant predictor variables
summary(mnb2 <- glm.nb(crime_count ~ scenic_rating + 
                                    health_deprivation_and_disability_score + 
                                    barriers_to_housing_and_services_score + 
                                    living_environment_score + 
                                    population_density_area_hectares, 
                      data=crime_subset_df))
```

The results of the negative binomial regression model shows that predictor variables income_score_rate, employment_score_rate, education_skills_and_training_score, are now no longer significant. Thus, we run another model excluding these variables and observe that following predictor variables do exert a statistically significant effect on the crime count (with at least a p-value<0.01):

* For one-unit **increase in scenic rating**, the expected log count of the crime count **decreases** by 0.57 (2 s.f.)
* For one-unit **increase in health and disability deprivation score**, the expected log count of the crime count **increases** by 0.093 (2 s.f.)
* For one-unit **increase in barriers to housing and services score**, the expected log count of the crime count **increases** by 0.0029 (2 s.f.)
* For one-unit **increase in living environment score**, the expected log count of the crime count **increases** by 0.028 (2 s.f.)
* For one-unit **increase in population density**, the expected log count of the crime count **increases** by 0.0025 (2 s.f.)

We also see from the AIC scores and drop in deviance test below between mnb3 (just containing scenic rating) and mnb2 (containing all other significant predictors), that there is evidence to suggest that the larger model produces significant improvement.

We can conclude from mnb2 that after controlling for predictor variables - health_deprivation_and_disability_score, barriers_to_housing_and_services_score, living_environment_score, population_density_area_hectares - there is evidence to suggest that crime count differs significantly according to scenic rating of an LSOA.

```{r}

# Test for drop in deviance between a negative binomial regression using just scenic rating vs more predictors
summary(mnb3 <- glm.nb(crime_count ~ scenic_rating,
                       data=crime_subset_df))
anova(mnb3, mnb2, test = "Chisq")
```

QUESTIONS:
* is the last conclusion correctly stated/definitely valid?
* Does the overdispersion test make the results of the model entirely useless? Does the negative binomial regression model entirely address the previous violation?
* Is it correct to interpret the best model as the one that (potentially contains a number of the predictors and) is ranked highest when we do some kind of model comparison, such as comparing AIC (or drop in deviance)?
* From this analysis, is it possible to say anything about the relationship between the predictor variables? Other than being able to say that when we control for X variable, Y is still signifiant.



So far, the above analysis has only taken into account crime counts irrespective of the type of crime. If we start to explore individual crime types, we see that the *minor* crime of **burglary in a dwelling** is the only crime type where the number of these crimes increases as the **scenic rating increases** (see below - non negative estimate value for scenic rating).

```{r}
library(AER)

# crime_types <- unique(df$crime_category)
# print(crime_types)
# for (i in crime_types) {
# 
#   subset_df = df[ which(df$crime_category==i), ]
#   print(i)
#   print(summary(m1 <- glm(crime_count ~ scenic_rating+
#                                 income_score_rate +
#                                 employment_score_rate +
#                                 education_skills_and_training_score +
#                                 health_deprivation_and_disability_score +
#                                 barriers_to_housing_and_services_score +
#                                 living_environment_score +
#                                 population_density_area_hectares,
#                         family="poisson",
#                         data=subset_df)))
# 
# }

minor_burg_dwell_df = df[ which(df$crime_category=="minor_burglary_in_a_dwelling"),]

summary(m6 <- glm(crime_count ~ scenic_rating +
                                income_score_rate +
                                employment_score_rate +
                                education_skills_and_training_score +
                                health_deprivation_and_disability_score +
                                barriers_to_housing_and_services_score +
                                living_environment_score +
                                population_density_area_hectares,
                        family="poisson",
                        data=minor_burg_dwell_df))

dispersiontest(m6)
```
